{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8295e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "WORDLIST_LOCATION = os.getenv(\"WORDLIST_LOCATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25bb080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_only = \"[a-z]\"\n",
    "\n",
    "wordlist = None\n",
    "with open(WORDLIST_LOCATION) as f:\n",
    "    wordlist = f.read()\n",
    "# with open('cleanlist.txt') as f:\n",
    "#     wordlist = f.read()\n",
    "\n",
    "wordlist = wordlist.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45b1ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [28, 239503, 25417], 'b': [23, 155339, 18413], 'c': [29, 303414, 32108], 'd': [31, 174945, 18733], 'e': [27, 135433, 14197], 'f': [24, 101370, 11893], 'g': [23, 92884, 10953], 'h': [28, 132135, 13743], 'i': [25, 138272, 13199], 'y': [15, 7611, 1143], 'j': [18, 21555, 2840], 'k': [20, 29418, 3952], 'l': [22, 85033, 10002], 'm': [27, 185652, 19805], 'n': [22, 149792, 13459], 'o': [23, 125685, 12681], 'p': [25, 354009, 34860], 'q': [19, 16578, 1793], 'r': [25, 153034, 16783], 's': [25, 363463, 38764], 't': [29, 170673, 18819], 'u': [22, 243503, 22766], 'v': [20, 47077, 5329], 'w': [19, 52341, 6559], 'x': [16, 4593, 507], 'z': [22, 11388, 1387], '': [0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "lengths = {}\n",
    "# {letter: [max_length, letter_count, word_count]}\n",
    "for word in wordlist:\n",
    "    current_letter = word[:1]\n",
    "    try:\n",
    "        current_max = lengths[current_letter][0]\n",
    "        lengths.update({word[:1]: [\n",
    "            lengths[current_letter][0], \n",
    "            (lengths[current_letter][1] + len(word)),\n",
    "            lengths[current_letter][2] + 1\n",
    "        ]})\n",
    "        if len(word) > current_max:\n",
    "            lengths.update({word[:1]: [\n",
    "                len(word), \n",
    "                lengths[current_letter][1],\n",
    "                lengths[current_letter][2]\n",
    "            ]})\n",
    "    except:\n",
    "        lengths.update({word[:1]: [\n",
    "            len(word), \n",
    "            len(word), \n",
    "            1\n",
    "        ]})\n",
    "\n",
    "print(lengths)\n",
    "\n",
    "lengths = dict(sorted(lengths.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0239572",
   "metadata": {},
   "source": [
    "Letter count per letter per word distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b7e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 0.1102\n",
      "B 0.0403\n",
      "C 0.0833\n",
      "D 0.0652\n",
      "E 0.0596\n",
      "F 0.0323\n",
      "G 0.0266\n",
      "H 0.026\n",
      "I 0.0506\n",
      "J 0.0063\n",
      "K 0.0287\n",
      "L 0.0253\n",
      "M 0.0509\n",
      "N 0.0237\n",
      "O 0.0249\n",
      "P 0.0824\n",
      "Q 0.0038\n",
      "R 0.0599\n",
      "S 0.0941\n",
      "T 0.0443\n",
      "U 0.017\n",
      "V 0.0254\n",
      "W 0.0088\n",
      "X 0.0015\n",
      "Y 0.0023\n",
      "Z 0.0066\n"
     ]
    }
   ],
   "source": [
    "letter_count_sum = 0\n",
    "for item in lengths:\n",
    "    letter_count_sum += lengths[item][1]\n",
    "\n",
    "for item in lengths:\n",
    "    if item != \"\":\n",
    "        print(item, np.round(lengths[item][1] / letter_count_sum,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2fa83",
   "metadata": {},
   "source": [
    "Word count per letter  distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8b8d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 3.2109\n",
      "B 4.5155\n",
      "C 3.6551\n",
      "D 4.0086\n",
      "E 4.1064\n",
      "F 4.8824\n",
      "G 5.1183\n",
      "H 5.2308\n",
      "I 4.4171\n",
      "J 7.0539\n",
      "K 5.0379\n",
      "L 5.1738\n",
      "M 4.2717\n",
      "N 5.3666\n",
      "O 5.2932\n",
      "P 3.6585\n",
      "Q 7.9931\n",
      "R 4.1072\n",
      "S 3.4155\n",
      "T 4.46\n",
      "U 5.8725\n",
      "V 5.275\n",
      "W 6.6449\n",
      "X 9.0835\n",
      "Y 8.4095\n",
      "Z 7.0715\n"
     ]
    }
   ],
   "source": [
    "word_count_sum = 0\n",
    "for item in lengths:\n",
    "    word_count_sum += lengths[item][2]\n",
    "\n",
    "for item in lengths:\n",
    "    if item != \"\":\n",
    "        print(item, np.round(abs(np.log2(lengths[item][2] / word_count_sum)),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e309057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 1.2158\n",
      "B 1.7097\n",
      "C 1.384\n",
      "D 1.5178\n",
      "E 1.5548\n",
      "F 1.8487\n",
      "G 1.938\n",
      "H 1.9806\n",
      "I 1.6725\n",
      "J 7.0539\n",
      "K 1.9076\n",
      "L 1.959\n",
      "M 1.6175\n",
      "N 5.3666\n",
      "O 5.2932\n",
      "P 1.3853\n",
      "Q 7.9931\n",
      "R 1.5552\n",
      "S 1.2932\n",
      "T 1.6887\n",
      "U 5.8725\n",
      "V 1.9973\n",
      "W 6.6449\n",
      "X 9.0835\n",
      "Y 8.4095\n",
      "Z 7.0715\n"
     ]
    }
   ],
   "source": [
    "word_rebalanced_sum = 0\n",
    "for item in lengths:\n",
    "    if item != \"\":\n",
    "        word_rebalanced_sum += abs(np.log2(lengths[item][2] / word_count_sum))\n",
    "\n",
    "word_rebalanced_avg = word_rebalanced_sum / 26\n",
    "\n",
    "for item in lengths:\n",
    "    if item != \"\" and abs(np.log2(lengths[item][2] / word_count_sum)) > word_rebalanced_avg:\n",
    "        print(item, np.round(abs(np.log2(lengths[item][2] / word_count_sum)), 4))\n",
    "    if item != \"\" and abs(np.log2(lengths[item][2] / word_count_sum)) <= word_rebalanced_avg:\n",
    "        print(item, np.round(abs(np.log2(lengths[item][2] / word_count_sum)) / (word_rebalanced_avg / 2), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8dadc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4662849\n",
      "4662849\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for item in lengths:\n",
    "    sum += lengths[item][2]\n",
    "\n",
    "print(sum)\n",
    "print(len(wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eedf4a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 10, 'B': 9, 'C': 10, 'D': 10, 'E': 10, 'F': 9, 'G': 9, 'H': 9, 'I': 10, 'J': 8, 'K': 9, 'L': 9, 'M': 9, 'N': 9, 'O': 9, 'P': 10, 'Q': 9, 'R': 10, 'S': 9, 'T': 9, 'U': 9, 'V': 9, 'W': 8, 'X': 8, 'Y': 7, 'Z': 8}\n"
     ]
    }
   ],
   "source": [
    "avg_letters = {}\n",
    "for item in lengths:\n",
    "    avg_letters.update({item: int(lengths[item][1] / lengths[item][2])})\n",
    "\n",
    "print(avg_letters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
